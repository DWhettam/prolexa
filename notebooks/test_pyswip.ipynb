{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning pyswip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/gleech/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import sys; sys.version\n",
    "from pyswip import Prolog\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "import contractions\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from enum import Enum\n",
    "\n",
    "sys.path.append(\"../python\")\n",
    "from POS_tagger import Tagger\n",
    "\n",
    "#pl = Prolog()\n",
    "#pl.consult(PROLEXA_PATH + \"prolexa.pl\")\n",
    "\n",
    "PROLEXA_PATH = \"../prolog/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports (consults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PartsOfSpeech\n",
    "# https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html\n",
    "class POS(Enum) :\n",
    "    DETERMINER = \"DT\"\n",
    "    ADVERB = \"RB\"\n",
    "    PROPNOUN = \"NNP\"\n",
    "    PROPNOUN_2 = \"PROPN\"\n",
    "    NOUN = \"NN\"\n",
    "    VERB = \"VB\"\n",
    "    ADJECTIVE = \"JJ\"\n",
    "    PREPOSITION = \"IN\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-26 10:45:01,199 loading file /home/gleech/.flair/models/en-pos-ontonotes-v0.5.pt\n",
      "['NNP', 'VB', 'JJ']\n",
      "[]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prolog = Prolog()\n",
    "#_, _, tags = tagger.tag('Dan is mortal')\n",
    "#print(tags)\n",
    "\n",
    "#out = standardise_tags(tags)\n",
    "out = escape_and_call_prolexa(prolog, 'Dan is broad')\n",
    "                              #'every lion is mortal')\n",
    "print(out)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tagger = Tagger()\n",
    "\n",
    "\n",
    "PROLOG_DET_REGEX = r\"determiner\\([a-z],X=>B,X=>H,\\[\\(H:-B\\)\\]\\)(.*)\"\n",
    "PROLOG_DET = \"determiner(p,X=>B,X=>H,[(H:-B)]) --> [{}].\\n\"\n",
    "\n",
    "\n",
    "def reset_grammar() :\n",
    "    lines = get_prolog_grammar(PROLEXA_PATH, original=True)\n",
    "    write_new_grammar(PROLEXA_PATH, lines)\n",
    "\n",
    "\n",
    "def lemmatise(word) :\n",
    "    wnl = WordNetLemmatizer()\n",
    "    \n",
    "    return wnl.lemmatize(word, 'n')\n",
    "\n",
    "\n",
    "def is_plural(word):\n",
    "    lemma = lemmatise(word)\n",
    "    plural = True if word is not lemma else False\n",
    "    return plural, lemma\n",
    "\n",
    "\n",
    "def handle_utterance_str(text) :\n",
    "    if text[0] != \"'\" and text[0] != '\"' :\n",
    "        text = f'\"{text}\"'\n",
    "    \n",
    "    text = text.replace('\"', '\\\"')\n",
    "    text = text.replace(\"'\", '\\\"')\n",
    "    \n",
    "    return \"handle_utterance(1,{},Output)\".format(text)\n",
    "\n",
    "\n",
    "def standardised_query(pl, text) :\n",
    "    text = contractions.fix(text)\n",
    "    text = lemmatise(text)\n",
    "    _, _, tags = tagger.tag(text)\n",
    "    tags = standardise_tags(tags)\n",
    "    #return escape_and_call_prolexa(pl, text)\n",
    "    return tags, text\n",
    "\n",
    "\n",
    "# for queries, not knowledge loading\n",
    "def standardise_tags(tags) :\n",
    "    std = []\n",
    "    for tag in tags :\n",
    "        if POS.VERB.value in tag :\n",
    "            std.append( POS.VERB.value)\n",
    "        if POS.ADVERB.value in tag :\n",
    "            std.append( POS.ADVERB.value)\n",
    "        if POS.ADJECTIVE.value in tag :\n",
    "            std.append( POS.ADJECTIVE.value)\n",
    "        if POS.NOUN.value in tag and tag != POS.PROPNOUN.value :\n",
    "            std.append( POS.NOUN.value)\n",
    "        if tag == POS.PROPNOUN.value :\n",
    "            std.append(POS.PROPNOUN.value)\n",
    "    return std\n",
    "    \n",
    "\n",
    "def get_tags(tagger, text) :\n",
    "    _, _, tags = tagger.tag(text)\n",
    "    tags = standardise_tags(tags)\n",
    "    return tags\n",
    "\n",
    "\n",
    "def get_prolog_grammar(path, original=False) :\n",
    "    if original :\n",
    "        file = \"prolexa_grammar_base.pl\"\n",
    "    else :\n",
    "        file = \"prolexa_grammar.pl\"\n",
    "    \n",
    "    f = open(path + file, \"r\")\n",
    "    lines = f.readlines()\n",
    "    f.close()\n",
    "    \n",
    "    return lines\n",
    "\n",
    "\n",
    "def write_new_grammar(path, lines) :\n",
    "    f = open(path + \"prolexa_grammar.pl\", \"w\")\n",
    "    lines = \"\".join(lines)\n",
    "    f.write(lines)\n",
    "    f.close()\n",
    "    \n",
    "    \n",
    "def handle_determiner(text, tags) :\n",
    "    start = '--> ['\n",
    "    end = ']'\n",
    "    exists = False\n",
    "    input_word = text[tags.index('DT')]\n",
    "    for det_idx, det_line in enumerate(lines[idx:]):                                                \n",
    "        if not(re.match(r\"determiner\\([a-z],X=>B,X=>H,\\[\\(H:-B\\)\\]\\)(.*)\", det_line)):\n",
    "            det_idx = det_idx + idx   \n",
    "            if tags:\n",
    "                tags.remove('DT')\n",
    "            if text:\n",
    "                text.remove(input_word)\n",
    "            break\n",
    "        line_word = (det_line.split(start))[1].split(end)[0]  \n",
    "        if input_word == line_word:                    \n",
    "            exists = True\n",
    "            if tags:\n",
    "                tags.remove('DT')\n",
    "            if text:\n",
    "                text.remove(input_word)\n",
    "            break \n",
    "\n",
    "    if not exists:\n",
    "        plural, _ = is_plural(input_word)\n",
    "        if plural:\n",
    "            new_line = \"determiner(p,X=>B,X=>H,[(H:-B)]) --> [{}].\\n\".format(input_word) \n",
    "        else:\n",
    "            new_line = \"determiner(s,X=>B,X=>H,[(H:-B)]) --> [{}].\\n\".format(input_word) \n",
    "        lines.insert(det_idx, new_line)\n",
    "\n",
    "\n",
    "def update_rules(tagger, text):\n",
    "    text = text.lower()\n",
    "    tags = get_tags(tagger, text)\n",
    "    print(tags)\n",
    "    text = text.split(' ')\n",
    "    start = ''\n",
    "    end = ''\n",
    "    lines = get_prolog_grammar(PROLEXA_PATH)\n",
    "    myiter = iter(lines)\n",
    "    \n",
    "    for idx, line in enumerate(myiter):\n",
    "        if not text:\n",
    "            break\n",
    "        \n",
    "        if ('DT' in tags) and re.match(r\"determiner\\([a-z],X=>B,X=>H,\\[\\(H:-B\\)\\]\\)(.*)\", line):\n",
    "            start = '--> ['\n",
    "            end = ']'\n",
    "            exists = False\n",
    "            input_word = text[tags.index('DT')]\n",
    "            for det_idx, det_line in enumerate(lines[idx:]):                                                \n",
    "                if not(re.match(r\"determiner\\([a-z],X=>B,X=>H,\\[\\(H:-B\\)\\]\\)(.*)\", det_line)):\n",
    "                    det_idx = det_idx + idx   \n",
    "                    if tags:\n",
    "                        tags.remove('DT')\n",
    "                    if text:\n",
    "                        text.remove(input_word)\n",
    "                    break\n",
    "                line_word = (det_line.split(start))[1].split(end)[0]  \n",
    "                if input_word == line_word:                    \n",
    "                    exists = True\n",
    "                    if tags:\n",
    "                        tags.remove('DT')\n",
    "                    if text:\n",
    "                        text.remove(input_word)\n",
    "                    break \n",
    "\n",
    "            if not exists:\n",
    "                plural, _ = is_plural(input_word)\n",
    "                if plural:\n",
    "                    new_line = \"determiner(p,X=>B,X=>H,[(H:-B)]) --> [{}].\\n\".format(input_word) \n",
    "                else:\n",
    "                    new_line = \"determiner(s,X=>B,X=>H,[(H:-B)]) --> [{}].\\n\".format(input_word) \n",
    "                lines.insert(det_idx, new_line)\n",
    "\n",
    "                    \n",
    "        if ('NN' in tags) and re.match(r\"pred\\((.*)[1],\\[(.*)\\]\\)\\.\", line): \n",
    "            start = 'pred('\n",
    "            end = ', '\n",
    "            exists = False\n",
    "            new_line = ''\n",
    "            input_word = text[tags.index('NN')]\n",
    "            for noun_idx, noun_line in enumerate(lines[idx:]):\n",
    "                if not(re.match(r\"pred\\((.*)[1],\\[(.*)\\]\\)\\.\", noun_line)):\n",
    "                    noun_idx = noun_idx + idx   \n",
    "                    if tags:\n",
    "                        tags.remove('NN')\n",
    "                    if text:\n",
    "                        text.remove(input_word)\n",
    "                    break\n",
    "                line_word = (noun_line.split(start))[1].split(end)[0]\n",
    "                if input_word == line_word:\n",
    "                    if (re.match(r\"pred\\((.*)[1](.*)n\\/(.*)\\]\\)\\.\", noun_line)):\n",
    "                        exists = True\n",
    "                        if tags:\n",
    "                            tags.remove('NN')\n",
    "                        if text:\n",
    "                            text.remove(input_word)\n",
    "                        break\n",
    "                    else:\n",
    "                        noun_idx = noun_idx + idx\n",
    "                        insert_idx = noun_line.index(']).')\n",
    "                        new_line = noun_line[:insert_idx] + ',n/' + input_word + noun_line[insert_idx:]\n",
    "                        lines[noun_idx] = new_line\n",
    "                        exists = True\n",
    "                        if tags:\n",
    "                            tags.remove('NN')\n",
    "                        if text:\n",
    "                            text.remove(input_word)\n",
    "                        break\n",
    "\n",
    "            if not exists:\n",
    "                plural, lemma = is_plural(input_word)\n",
    "                if plural:\n",
    "                    input_word = lemma\n",
    "                if new_line == '':\n",
    "                    new_line = 'pred(' + input_word + ', 1,[n/' + input_word + ']).\\n'\n",
    "                lines.insert(noun_idx, new_line)\n",
    "                \n",
    "                \n",
    "        if ('JJ' in tags) and re.match(r\"pred\\((.*)[1],\\[(.*)\\]\\)\\.\", line): \n",
    "            start = 'pred('\n",
    "            end = ', '\n",
    "            exists = False\n",
    "            new_line = ''\n",
    "            input_word = text[tags.index('JJ')]\n",
    "            for noun_idx, noun_line in enumerate(lines[idx:]):\n",
    "                if not(re.match(r\"pred\\((.*)[1],\\[(.*)\\]\\)\\.\", noun_line)):\n",
    "                    noun_idx = noun_idx + idx   \n",
    "                    if tags:\n",
    "                        tags.remove('JJ')\n",
    "                    if text:\n",
    "                        text.remove(input_word)\n",
    "                    break\n",
    "                line_word = (noun_line.split(start))[1].split(end)[0]\n",
    "                if input_word == line_word:\n",
    "                    if (re.match(r\"pred\\((.*)[1](.*)a\\/(.*)\\]\\)\\.\", noun_line)):\n",
    "                        exists = True\n",
    "                        if tags:\n",
    "                            tags.remove('JJ')\n",
    "                        if text:\n",
    "                            text.remove(input_word)\n",
    "                        break\n",
    "                    else:\n",
    "                        noun_idx = noun_idx + idx\n",
    "                        insert_idx = noun_line.index(']).')\n",
    "                        new_line = noun_line[:insert_idx] + ',a/' + input_word + noun_line[insert_idx:]\n",
    "                        lines[noun_idx] = new_line\n",
    "                        exists = True\n",
    "                        if tags:\n",
    "                            tags.remove('JJ')\n",
    "                        if text:\n",
    "                            text.remove(input_word)\n",
    "                        break\n",
    "\n",
    "            if not exists:\n",
    "                plural, lemma = is_plural(input_word)\n",
    "                if plural:\n",
    "                    input_word = lemma\n",
    "                if new_line == '':\n",
    "                    new_line = 'pred(' + input_word + ', 1,[a/' + input_word + ']).\\n'\n",
    "                lines.insert(noun_idx, new_line)\n",
    "                \n",
    "        if ('VB' in tags) and re.match(r\"pred\\((.*)[1],\\[(.*)\\]\\)\\.\", line): \n",
    "            start = 'pred('\n",
    "            end = ', '\n",
    "            exists = False\n",
    "            new_line = ''\n",
    "            input_word = text[tags.index('VB')]\n",
    "            for noun_idx, noun_line in enumerate(lines[idx:]):\n",
    "                if not(re.match(r\"pred\\((.*)[1],\\[(.*)\\]\\)\\.\", noun_line)):\n",
    "                    noun_idx = noun_idx + idx   \n",
    "                    if tags:\n",
    "                        tags.remove('VB')\n",
    "                    if text:\n",
    "                        text.remove(input_word)\n",
    "                    break\n",
    "                line_word = (noun_line.split(start))[1].split(end)[0]\n",
    "                if input_word == line_word:\n",
    "                    if (re.match(r\"pred\\((.*)[1](.*)v\\/(.*)\\]\\)\\.\", noun_line)):\n",
    "                        exists = True\n",
    "                        if tags:\n",
    "                            tags.remove('VB')\n",
    "                        if text:\n",
    "                            text.remove(input_word)\n",
    "                        break\n",
    "                    else:\n",
    "                        noun_idx = noun_idx + idx\n",
    "                        insert_idx = noun_line.index(']).')\n",
    "                        new_line = noun_line[:insert_idx] + ',v/' + input_word + noun_line[insert_idx:]\n",
    "                        lines[noun_idx] = new_line\n",
    "                        exists = True\n",
    "                        if tags:\n",
    "                            tags.remove('VB')\n",
    "                        if text:\n",
    "                            text.remove(input_word)\n",
    "                        break\n",
    "            if not exists:\n",
    "                plural, lemma = is_plural(input_word)\n",
    "                if plural:\n",
    "                    input_word = lemma\n",
    "                if new_line == '':\n",
    "                    new_line = 'pred(' + input_word + ', 1,[v/' + input_word + ']).\\n'\n",
    "                lines.insert(noun_idx, new_line)\n",
    "                        \n",
    "        if ('NNP' in tags) and re.match(r\"proper_noun\\(s(.*) -->(.*)\\]\\.\", line):\n",
    "            start = '--> ['\n",
    "            end = ']'\n",
    "            exists = False\n",
    "            input_word = text[tags.index('NNP')]\n",
    "            for det_idx, det_line in enumerate(lines[idx:]):                                                \n",
    "                if not(re.match(r\"proper_noun\\(s(.*) -->(.*)\\]\\.\", det_line)):\n",
    "                    det_idx = det_idx + idx   \n",
    "                    if tags:\n",
    "                        tags.remove('NNP')\n",
    "                    if text:\n",
    "                        text.remove(input_word)\n",
    "                    break\n",
    "                line_word = (det_line.split(start))[1].split(end)[0]  \n",
    "                if input_word == line_word:                    \n",
    "                    exists = True\n",
    "                    if tags:\n",
    "                        tags.remove('NNP')\n",
    "                    if text:\n",
    "                        text.remove(input_word)\n",
    "                    break \n",
    "\n",
    "            if not exists:             \n",
    "                new_line = \"proper_noun(s,{}) --> [{}].\\n\".format(input_word, input_word) \n",
    "                lines.insert(det_idx, new_line)        \n",
    " \n",
    "    print([line for line in lines if \"Dan\" in line])\n",
    "    write_new_grammar(PROLEXA_PATH, lines)\n",
    "\n",
    "\n",
    "\n",
    "def escape_and_call_prolexa(pl, text) :\n",
    "    libPrefix = \"prolexa:\"\n",
    "    update_rules(tagger, text)\n",
    "    return ''\n",
    "    \n",
    "    #pl.consult(PROLEXA_PATH + \"prolexa.pl\")\n",
    "    #return pl.query(libPrefix + handle_utterance_str(text))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = Prolog()\n",
    "pl.consult(PROLEXA_PATH + \"prolexa.pl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'VB'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wnl = WordNetLemmatizer()\n",
    "for word in \"doesn't think about girls\".split(\" \") :\n",
    "    print( wnl.lemmatize(word) )\n",
    "    \n",
    "_, _, tags = tagger.tag(\"doesn't think lions are mortals\")\n",
    "standardise_tags(tags)\n",
    "\n",
    "contractions.fix(\"doesn't think about girls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.consult(\"trains.pl\")\n",
    "STATIONS = [ans[\"S\"] for ans in pl.query(\"station(S)\")]\n",
    "STATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.assertz(\"father(michael,john)\")\n",
    "pl.assertz(\"father(michael,gina)\")\n",
    "pl = Prolog()\n",
    "\n",
    "for soln in pl.query(\"father(X,Y)\"):\n",
    "    print(soln[\"X\"], \"is the father of\", soln[\"Y\"])\n",
    "\n",
    "# michael is the father of john\n",
    "# michael is the father of gina\n",
    "\n",
    "childrenOfMichael = pl.query(\"father(michael,X)\")\n",
    "list(childrenOfMichael)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyswip_env",
   "language": "python",
   "name": "pyswip_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
